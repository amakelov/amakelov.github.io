<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Mandala: Python programs that save, query and version themselves | Alex Makelov</title>
  <link rel="stylesheet" href="/style.css">
</head>
<body>

<p class="back-link"><a href="/">‚Üê Back to home</a></p>

<article>
  <h1>Mandala: Python programs that save, query and version themselves</h1>
  <h2 id=tldr>tl;dr</h2><p>Your code and its execution traces contain enough information to save, query and
version computations without extra boilerplate. <a href=https://github.com/amakelov/mandala><code>mandala</code></a>
is a persistent memoization cache on steroids that lets you tap into this
information. It</p><ul><li>turns Python programs - composed of function calls, collections and control
flow - into interlinked, persistent data as they execute.</li><li>can be queried by directly pattern-matching against such programs, returning
tables of values in the cache satisfying the computational relationships
of the program</li><li>tracks the dependencies of each memoized function call, automatically
detecting when a change in the code may require recomputation.</li></ul><p>This radically simplifies data management for computational artifacts, leading
to efficient reuse of computations, clear code, fewer bugs, easier
reproducibility, and improved developer productivity. The project is still in
active development, and not optimized for performance. Its primary use case is
data science and machine learning experiments.</p><p><img loading=lazy src=/videos/tldr.gif alt=preview></p><h2 id=introduction>Introduction</h2><p>They finally figured out how the Roman Empire <em>actually</em> fell, and it was
this file: <code>model_param=0.1_best_VERSION2_preprocess=True_final_FIXED.pkl</code>. ...OK,
we all agree this filename's terrible - but why exactly? Its job is to tell the
story of a computation. But computations are more expressive, structured,
and malleable than filenames. So, it's no wonder you run into awkwardness,
confusion and bugs when you try to turn one into the other. This impedance
mismatch is at the root of the <strong>computational data management problem</strong>.</p><p>By contrast, the code producing the file's contents is a far superior telling of
its story:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>load_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>preprocess</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span> <span class=o>=</span> <span class=n>preprocess_data</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>train_v2</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>param</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span></span></code></pre></div><p>It makes it clear how logic and parameters combine to produce <code>model</code>.
More subtly, implicit in the code are the invariant-across-executions
computational relationships that we typically want to query (e.g., "find all the
models trained on a particular dataset <code>X</code>"). This raises a question:</p><blockquote><p><em>If the code already contains all this structured information about the
meaning of its results, why not just make it its own storage interface?</em></p></blockquote><p><a href=https://github.com/amakelov/mandala><code>mandala</code></a> is a tool that implements this
idea. It turns function calls into interlinked, queriable, content-versioned data that
is automatically co-evolved with your codebase. By applying different semantics
to this data, the same ordinary Python code, including control flow
and collections, can be used to not only compute, but also save, load, query,
batch-compute, and combinations of those.</p><p><a href=https://wandb.ai/site>Unlike</a> <a href=https://github.com/IDSIA/sacred>existing</a>
<a href=https://mlflow.org/>frameworks</a> <a href=https://github.com/iterative/dvc>addressing</a>
various parts of the problem,
<code>mandala</code> bakes data management logic deeper into Python itself, and
intentionally has few interfaces, concepts, and domain-specific features to
speak of. Instead, it lets you do your work mostly through plain code. This
direct approach makes it much more natural and less error-prone to iteratively
compose and query complex experiments.</p><h3 id=outline>Outline</h3><p>This blog post is a brief, somewhat programming-languages-themed tour of
the unusual core features that work together to make this possible:</p><ul><li><a href=#python-integrated-memoization>memoization</a> aligned with core Python
features turns programs into <em>imperative</em> computation/storage/query interfaces
and enables incremental computing by default;</li><li><a href=#pattern-matching-queries>pattern-matching queries</a> turn programs into
<em>declarative</em> query interfaces to analogous computations in the entire storage;</li><li><a href=#per-call-versioning-and-dependency-tracking>per-call versioning and dependency
tracking</a> enable further
fine-grained incremental computation by tracking changes in the dependencies of
each memoized call.</li></ul><p>There is a companion notebook for this blog post that you can <a href=https://github.com/amakelov/mandala/blob/master/tutorials/03_advanced.ipynb>read
here</a>
or<div align=center><a href=https://colab.research.google.com/github/amakelov/mandala/blob/master/tutorials/03_advanced.ipynb><img src=https://colab.research.google.com/assets/colab-badge.svg alt="Open In Colab"></a></div></p><h2 id=python-integrated-memoization>Python-integrated memoization</h2><p>While <a href=https://en.wikipedia.org/wiki/Memoization>memoization</a> is typically used
as a mere cache, it can be much more. Imagine a complex piece of code where
<em>every</em> function call has been memoized in a shared cache. Such code effectively
becomes a map of the cache that you can traverse by (efficiently) retracing its
steps, no matter how complex the logic. You can also incrementally build
computations by just adding to this code: you get through the memoized part
fast, and do the new work. This is especially useful in interactive environments
like <a href=https://jupyter.org/>Jupyter notebooks</a>.</p><h3 id=collections-lazy-reads-and-control-flow>Collections, lazy reads, and control flow</h3><p>To illustrate, here's a simple machine learning pipeline for a do-it-yourself
random forest classifier:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=nd>@op</span> <span class=c1># core mandala decorator</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>generate_data</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>ndarray</span><span class=p>,</span> <span class=n>ndarray</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=o>...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nd>@op</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_and_eval_tree</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>seed</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Tuple</span><span class=p>[</span><span class=n>DecisionTreeClassifier</span><span class=p>,</span> <span class=nb>float</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>    <span class=o>...</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl><span class=nd>@op</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>eval_forest</span><span class=p>(</span><span class=n>trees</span><span class=p>:</span><span class=n>List</span><span class=p>[</span><span class=n>DecisionTreeClassifier</span><span class=p>],</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>float</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># get majority vote accuracy</span>
</span></span><span class=line><span class=cl>    <span class=o>...</span>
</span></span></code></pre></div><p>We can compose these functions in the obvious way to train a few trees and
evaluate the resulting forest:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>with</span> <span class=n>storage</span><span class=o>.</span><span class=n>run</span><span class=p>():</span> <span class=c1># memoization context manager</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>generate_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>trees</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>seed</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span> <span class=c1># can&#39;t grow trees without seeds :)</span>
</span></span><span class=line><span class=cl>        <span class=n>tree</span><span class=p>,</span> <span class=n>acc</span> <span class=o>=</span> <span class=n>train_and_eval_tree</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>seed</span><span class=o>=</span><span class=n>seed</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>trees</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>tree</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>forest_acc</span> <span class=o>=</span> <span class=n>eval_forest</span><span class=p>(</span><span class=n>trees</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span></code></pre></div><p>Note that we are passing the list <code>trees</code> of memoized values into another
memoized function. This incurs no storage duplication, because each element of
the list is stored separately, and <code>trees</code> behaves like a list of pointers to
storage locations, rather than a monolithic blob. This is one example of how
<code>mandala</code>'s memoization JustWorks‚Ñ¢ with Python's collections.</p><p>This compatibility lets you write algorithms that naturally operate on
collections of objects (which <em>do</em> come up in practice, e.g. aggregators, model
ensembling, clustering, chunking, ...) in the most straightforward way, while
still having intermediate results cached (and even <a href=#pattern-matching-with-collections-the-color-refinement-projection>declaratively
queriable</a>). The video below shows this in action by
incrementally evolving the workflow above with new logic and parameters:</p><p><details open><summary markdown=span>Show/hide video</summary>
<video width=100% controls>
<source src=../../videos/mem.mp4 type=video/mp4><source src=../../videos/mem.webm type=video/webm>Your browser does not support HTML5 video.</video></details></p><p>The video above illustrates</p><ul><li><strong>memoization as imperative query interface</strong>: you can get to any of the
computed quantities just by retracing the memoized code, or parts of it, again.</li><li><strong>laziness</strong>: when run against a persistent storage, <code>mandala</code> only reads from
disk when a value is needed for a new computation</li><li><strong>control flow</strong>: laziness is designed to do the least work compatible with
control flow - even though initially <code>acc</code> is a lazy reference, when the <code>if acc > 0.8:</code> statement is reached, this causes a read from the storage. This
applies more generally to collections: a lazy reference to a collection has no
elements, but e.g. iterating over it automatically loads (lazy) references to its
elements.</li></ul><h3 id=hierarchical-memoization-and-more-incremental-computing>Hierarchical memoization and (more) incremental computing</h3><p>There's still a major scalability problem - what if we had a workflow involving
not tens but thousands or even millions of function calls? Stepping through each
memoized call to get to a single final result (like we do with calls to
<code>train_and_eval_tree</code> here) - even with laziness - could take a long time.</p><p>The solution is simple: memoize large subprograms like that end-to-end by
abstracting them as a single (parametrized) memoized function. After all, <strong>every
time there is a large number of calls happening, they share some repetitive
structure that can be abstracted away</strong>. This way you can take "shortcuts" in the
memoization graph:</p><p><details open><summary markdown=span>Show/hide video</summary>
<video width=100% controls>
<source src=../../videos/sup.mp4 type=video/mp4><source src=../../videos/sup.webm type=video/webm>Your browser does not support HTML5 video.</video></details></p><p>The <code>@superop</code> decorator you see in the video is needed to indicate that a
memoized function is itself a composition of memoized functions. A few of the
nice things enabled by this:</p><ul><li><strong>shortcutting via memoization</strong>: the first time when you run the refactored
workflow, execution goes inside the body of <code>train_forest</code> and loops over all
the memoized calls to <code>train_and_eval_tree</code>, but the second time it has already
memoized the call to <code>train_forest</code> end-to-end and jumps right to the return
value. That's why the second run is faster!</li><li><strong>natively incremental computing</strong>: calling <code>train_forest</code> with a higher value of
<code>n_trees</code> does not do all its work from scratch: since it internally uses
memoized functions, it is able to (lazily) skip over the memoized calls and do
only the new work.</li></ul><h2 id=pattern-matching-queries>Pattern-matching queries</h2><p>Using memoization as a query interface relies on you knowing the "initial
conditions" from which to start stepping through the trail of memoized calls -
but this is not always a good fit. As a complement to this imperative interface,
you also have a <em>declarative</em> query interface over the entire storage. To
illustrate, consider where we might have left things with our random forest
example:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>In</span> <span class=p>[</span><span class=mi>23</span><span class=p>]:</span> <span class=k>with</span> <span class=n>storage</span><span class=o>.</span><span class=n>run</span><span class=p>():</span>
</span></span><span class=line><span class=cl>   <span class=o>...</span><span class=p>:</span>     <span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>generate_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>   <span class=o>...</span><span class=p>:</span>     <span class=k>for</span> <span class=n>n_trees</span> <span class=ow>in</span> <span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>,</span> <span class=p>):</span>
</span></span><span class=line><span class=cl>   <span class=o>...</span><span class=p>:</span>         <span class=n>trees</span> <span class=o>=</span> <span class=n>train_forest</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>n_trees</span><span class=p>)</span>
</span></span><span class=line><span class=cl>   <span class=o>...</span><span class=p>:</span>         <span class=n>forest_acc</span> <span class=o>=</span> <span class=n>eval_forest</span><span class=p>(</span><span class=n>trees</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span></code></pre></div><p>If this project went on for a while, you may not remember all the values of
<code>n_trees</code> you ran this with. Fortunately, this code contains the repeated
relationship between <code>X, y, n_trees, trees, forest_acc</code> you care about. In fact,
the values of these local variables after this code executes are in exactly this
relationship. Since every <code>@op</code>-decorated call links its inputs and outputs
behind the scenes, you can inspect the qualitative history of <code>forest_acc</code> in
this computation as a graph by calling <code>storage.draw_graph(forest_acc)</code>:</p><figure align=center class=align-center><!doctype html><svg width="286pt" height="375pt" viewBox="0 0 286.38 375" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 371)"><title>G</title><polygon fill="#fff" stroke="transparent" points="-4,4 -4,-371 282.38,-371 282.38,4 -4,4"/><g id="node1" class="node"><title>140658408547392</title><polygon fill="#cb4b16" stroke="transparent" points="37.5,0.5 37.5,-16.5 101.5,-16.5 101.5,0.5 37.5,0.5"/><polygon fill="none" stroke="#002b36" points="37.5,0.5 37.5,-16.5 101.5,-16.5 101.5,0.5 37.5,0.5"/><text text-anchor="start" x="40.5" y="-6.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#fdf6e3">forest_acc</text></g><g id="node2" class="node"><title>140656954281072</title><polygon fill="#cb4b16" stroke="transparent" points="229.5,-279.5 229.5,-296.5 242.5,-296.5 242.5,-279.5 229.5,-279.5"/><polygon fill="none" stroke="#002b36" points="229.5,-279.5 229.5,-296.5 242.5,-296.5 242.5,-279.5 229.5,-279.5"/><text text-anchor="start" x="232.5" y="-286.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#fdf6e3">y</text></g><g id="node6" class="node"><title>140656891611744</title><polygon fill="#fdf6e3" stroke="transparent" points="111.5,-226.5 111.5,-243.5 163.5,-243.5 163.5,-226.5 111.5,-226.5"/><polygon fill="none" stroke="#002b36" points="111.5,-226.5 111.5,-243.5 163.5,-243.5 163.5,-226.5 111.5,-226.5"/><text text-anchor="start" x="133.5" y="-233.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#002b36">X</text><polygon fill="#fdf6e3" stroke="transparent" points="163.5,-226.5 163.5,-243.5 195.5,-243.5 195.5,-226.5 163.5,-226.5"/><polygon fill="none" stroke="#002b36" points="163.5,-226.5 163.5,-243.5 195.5,-243.5 195.5,-226.5 163.5,-226.5"/><text text-anchor="start" x="176" y="-233.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#002b36">y</text><polygon fill="#fdf6e3" stroke="transparent" points="195.5,-226.5 195.5,-243.5 262.5,-243.5 262.5,-226.5 195.5,-226.5"/><polygon fill="none" stroke="#002b36" points="195.5,-226.5 195.5,-243.5 262.5,-243.5 262.5,-226.5 195.5,-226.5"/><text text-anchor="start" x="208" y="-233.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#002b36">n_trees</text><polygon fill="#268bd2" stroke="transparent" points="111.5,-209.5 111.5,-226.5 262.5,-226.5 262.5,-209.5 111.5,-209.5"/><polygon fill="none" stroke="#002b36" points="111.5,-209.5 111.5,-226.5 262.5,-226.5 262.5,-209.5 111.5,-209.5"/><text text-anchor="start" x="114.5" y="-216.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#fdf6e3">train_forest(X, y, n_trees)</text><polygon fill="#fdf6e3" stroke="transparent" points="111.5,-192.5 111.5,-209.5 262.5,-209.5 262.5,-192.5 111.5,-192.5"/><polygon fill="none" stroke="#002b36" points="111.5,-192.5 111.5,-209.5 262.5,-209.5 262.5,-192.5 111.5,-192.5"/><text text-anchor="start" x="162.5" y="-199.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#002b36">output_0</text></g><g id="edge2" class="edge"><title>140656954281072->140656891611744:y</title><path fill="none" stroke="#002b36" d="M228.63-283.93C217.07-277.75 194-264.61 184.14-253.27"/><polygon fill="#002b36" stroke="#002b36" points="187.11,-251.38 179.5,-244 180.85,-254.51 187.11,-251.38"/></g><g id="node7" class="node"><title>140658408549984</title><polygon fill="#fdf6e3" stroke="transparent" points="0.5,-86.5 0.5,-103.5 73.5,-103.5 73.5,-86.5 0.5,-86.5"/><polygon fill="none" stroke="#002b36" points="0.5,-86.5 0.5,-103.5 73.5,-103.5 73.5,-86.5 0.5,-86.5"/><text text-anchor="start" x="22" y="-93.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#002b36">trees</text><polygon fill="#fdf6e3" stroke="transparent" points="73.5,-86.5 73.5,-103.5 105.5,-103.5 105.5,-86.5 73.5,-86.5"/><polygon fill="none" stroke="#002b36" points="73.5,-86.5 73.5,-103.5 105.5,-103.5 105.5,-86.5 73.5,-86.5"/><text text-anchor="start" x="85.5" y="-93.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#002b36">X</text><polygon fill="#fdf6e3" stroke="transparent" points="105.5,-86.5 105.5,-103.5 137.5,-103.5 137.5,-86.5 105.5,-86.5"/><polygon fill="none" stroke="#002b36" points="105.5,-86.5 105.5,-103.5 137.5,-103.5 137.5,-86.5 105.5,-86.5"/><text text-anchor="start" x="118" y="-93.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#002b36">y</text><polygon fill="#268bd2" stroke="transparent" points="0.5,-69.5 0.5,-86.5 137.5,-86.5 137.5,-69.5 0.5,-69.5"/><polygon fill="none" stroke="#002b36" points="0.5,-69.5 0.5,-86.5 137.5,-86.5 137.5,-69.5 0.5,-69.5"/><text text-anchor="start" x="3.5" y="-76.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#fdf6e3">eval_forest(trees, X, y)</text><polygon fill="#fdf6e3" stroke="transparent" points="0.5,-52.5 0.5,-69.5 137.5,-69.5 137.5,-52.5 0.5,-52.5"/><polygon fill="none" stroke="#002b36" points="0.5,-52.5 0.5,-69.5 137.5,-69.5 137.5,-52.5 0.5,-52.5"/><text text-anchor="start" x="44.5" y="-59.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#002b36">output_0</text></g><g id="edge7" class="edge"><title>140656954281072->140658408549984:y</title><path fill="none" stroke="#002b36" d="M242.14-282.17C250.83-274.71 265.65-260.23 271.5-244 279.18-222.67 281.75-213.22 271.5-193c-31.58 62.31-57.2 94.42-123 97.29"/><polygon fill="#002b36" stroke="#002b36" points="148.57,-92.21 138.5,-95.5 148.42,-99.21 148.57,-92.21"/></g><g id="node3" class="node"><title>140656891622544</title><polygon fill="#cb4b16" stroke="transparent" points="18.5,-139.5 18.5,-156.5 54.5,-156.5 54.5,-139.5 18.5,-139.5"/><polygon fill="none" stroke="#002b36" points="18.5,-139.5 18.5,-156.5 54.5,-156.5 54.5,-139.5 18.5,-139.5"/><text text-anchor="start" x="21.5" y="-146.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#fdf6e3">trees</text></g><g id="edge5" class="edge"><title>140656891622544->140658408549984:trees</title><path fill="none" stroke="#002b36" d="M36.5-139.8c0 6.39000000000002.0 15.94.0 25.53"/><polygon fill="#002b36" stroke="#002b36" points="40,-114 36.5,-104 33,-114 40,-114"/></g><g id="node4" class="node"><title>140656954280256</title><polygon fill="#cb4b16" stroke="transparent" points="130.5,-279.5 130.5,-296.5 144.5,-296.5 144.5,-279.5 130.5,-279.5"/><polygon fill="none" stroke="#002b36" points="130.5,-279.5 130.5,-296.5 144.5,-296.5 144.5,-279.5 130.5,-279.5"/><text text-anchor="start" x="133.5" y="-286.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#fdf6e3">X</text></g><g id="edge1" class="edge"><title>140656954280256->140656891611744:X</title><path fill="none" stroke="#002b36" d="M137.5-279.8c0 6.38999999999999.0 15.94.0 25.53"/><polygon fill="#002b36" stroke="#002b36" points="141,-254 137.5,-244 134,-254 141,-254"/></g><g id="edge6" class="edge"><title>140656954280256->140658408549984:X</title><path fill="none" stroke="#002b36" d="M130.48-281.56C121.94-273.88 107.89-259.6 101.5-244c-22.31 54.52-13.21 75.19-12.1 129.78"/><polygon fill="#002b36" stroke="#002b36" points="92.9,-114.04 89.5,-104 85.9,-113.96 92.9,-114.04"/></g><g id="node5" class="node"><title>140656891618224</title><polygon fill="#cb4b16" stroke="transparent" points="190.5,-279.5 190.5,-296.5 210.5,-296.5 210.5,-279.5 190.5,-279.5"/><polygon fill="none" stroke="#002b36" points="190.5,-279.5 190.5,-296.5 210.5,-296.5 210.5,-279.5 190.5,-279.5"/><text text-anchor="start" x="193.5" y="-286.5" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#fdf6e3">a0</text></g><g id="edge3" class="edge"><title>140656891618224->140656891611744:n_trees</title><path fill="none" stroke="#002b36" d="M209.68-279.86C216.18-273.75 224.35-264.49 227.82-253.97"/><polygon fill="#002b36" stroke="#002b36" points="231.28,-254.44 229.5,-244 224.38,-253.28 231.28,-254.44"/></g><g id="edge4" class="edge"><title>140656891611744:output_0->140656891622544</title><path fill="none" stroke="#002b36" d="M110.5-200.5c-25.3.0-48.24 20.47-61.66 35.47"/><polygon fill="#002b36" stroke="#002b36" points="51.21,-162.42 42.09,-157.03 45.86,-166.93 51.21,-162.42"/></g><g id="edge8" class="edge"><title>140658408549984:output_0->140658408547392</title><path fill="none" stroke="#002b36" d="M69.5-53c0 8.42.0 17.76.0 25.62"/><polygon fill="#002b36" stroke="#002b36" points="73,-27.2 69.5,-17.2 66,-27.2 73,-27.2"/></g><g id="node8" class="node"><title>140656954282464</title><polygon fill="#268bd2" stroke="transparent" points="117.5,-350 117.5,-367 227.5,-367 227.5,-350 117.5,-350"/><polygon fill="none" stroke="#002b36" points="117.5,-350 117.5,-367 227.5,-367 227.5,-350 117.5,-350"/><text text-anchor="start" x="127" y="-357" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#fdf6e3">generate_data()</text><polygon fill="#fdf6e3" stroke="transparent" points="117.5,-333 117.5,-350 172.5,-350 172.5,-333 117.5,-333"/><polygon fill="none" stroke="#002b36" points="117.5,-333 117.5,-350 172.5,-350 172.5,-333 117.5,-333"/><text text-anchor="start" x="120.5" y="-340" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#002b36">output_0</text><polygon fill="#fdf6e3" stroke="transparent" points="172.5,-333 172.5,-350 227.5,-350 227.5,-333 172.5,-333"/><polygon fill="none" stroke="#002b36" points="172.5,-333 172.5,-350 227.5,-350 227.5,-333 172.5,-333"/><text text-anchor="start" x="175.5" y="-340" font-family="Helvetica,sans-Serif" font-weight="bold" font-size="10" fill="#002b36">output_1</text></g><g id="edge10" class="edge"><title>140656954282464:output_1->140656954281072</title><path fill="none" stroke="#002b36" d="M228.5-341c14.09.0 13.6 19.15 11.07 34.1"/><polygon fill="#002b36" stroke="#002b36" points="242.99,-306.19 237.55,-297.1 236.14,-307.6 242.99,-306.19"/></g><g id="edge9" class="edge"><title>140656954282464:output_0->140656954280256</title><path fill="none" stroke="#002b36" d="M144.5-333C144.5-324.37 143.14-314.9 141.62-307"/><polygon fill="#002b36" stroke="#002b36" points="145.02,-306.18 139.49,-297.14 138.18,-307.65 145.02,-306.18"/></g></g></svg></figure><p>This data makes it possible to directly point to the variable <code>forest_acc</code>
and issue a query for all values in the storage that have the same qualitative
computational history:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>In</span> <span class=p>[</span><span class=mi>42</span><span class=p>]:</span> <span class=n>storage</span><span class=o>.</span><span class=n>similar</span><span class=p>(</span><span class=n>forest_acc</span><span class=p>,</span> <span class=n>context</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>Pattern</span><span class=o>-</span><span class=n>matching</span> <span class=n>to</span> <span class=n>the</span> <span class=n>following</span> <span class=n>computational</span> <span class=n>graph</span> <span class=p>(</span><span class=nb>all</span> <span class=n>constraints</span> <span class=n>apply</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>a0</span> <span class=o>=</span> <span class=n>Q</span><span class=p>()</span> <span class=c1># input to computation; can match anything</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>generate_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>trees</span> <span class=o>=</span> <span class=n>train_forest</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y</span><span class=p>,</span> <span class=n>n_trees</span><span class=o>=</span><span class=n>a0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>forest_acc</span> <span class=o>=</span> <span class=n>eval_forest</span><span class=p>(</span><span class=n>trees</span><span class=o>=</span><span class=n>trees</span><span class=p>,</span> <span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=n>storage</span><span class=o>.</span><span class=n>df</span><span class=p>(</span><span class=n>a0</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>trees</span><span class=p>,</span> <span class=n>forest_acc</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>Out</span><span class=p>[</span><span class=mi>42</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>   <span class=n>a0</span>  <span class=n>y</span>           <span class=n>X</span>                            <span class=n>trees</span>  <span class=n>forest_acc</span>
</span></span><span class=line><span class=cl><span class=mi>2</span>   <span class=mi>5</span>  <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=o>...</span>  <span class=p>[[</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>0.0</span><span class=p>,</span> <span class=o>...</span>  <span class=p>[</span><span class=n>DecisionTreeC</span><span class=o>...</span>        <span class=mf>0.96</span>
</span></span><span class=line><span class=cl><span class=mi>3</span>  <span class=mi>10</span>  <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=o>...</span>  <span class=p>[[</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>0.0</span><span class=p>,</span> <span class=o>...</span>  <span class=p>[</span><span class=n>DecisionTreeC</span><span class=o>...</span>        <span class=mf>0.99</span>
</span></span><span class=line><span class=cl><span class=mi>0</span>  <span class=mi>15</span>  <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=o>...</span>  <span class=p>[[</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>0.0</span><span class=p>,</span> <span class=o>...</span>  <span class=p>[</span><span class=n>DecisionTreeC</span><span class=o>...</span>        <span class=mf>0.99</span>
</span></span><span class=line><span class=cl><span class=mi>1</span>  <span class=mi>20</span>  <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=o>...</span>  <span class=p>[[</span><span class=mf>0.0</span><span class=p>,</span> <span class=mf>0.0</span><span class=p>,</span> <span class=o>...</span>  <span class=p>[</span><span class=n>DecisionTreeC</span><span class=o>...</span>        <span class=mf>0.99</span>
</span></span></code></pre></div><p>The <code>context=True</code> option includes the values <code>forest_acc</code> depends on in the
table. In particular, this reveals all the values of <code>n_trees</code> this workflow
was ran with, and the intermediate results along the way.</p><p>Finally, you have an explicit counterpart to this implicit query interface: if
you copy-paste the code for the computational graph above into a <code>with storage.query():</code> block, <code>result</code> will be the same table as above.</p><h3 id=what-just-happened->What just happened? ü§Ø</h3><p>Behind the scenes, the computational graph that <code>forest_acc</code> is derived from
gets compiled to a SQL query over memoization tables. In the returned table,
each row is a matching of values to the variables that satisfies <em>all</em> the
computational relationships in the graph. This is the classical database concept
of <a href=https://en.wikipedia.org/wiki/Conjunctive_query>conjunctive queries</a>.</p><p>And here's (simplified) SQL code the pattern-matching query compiles to, where
you should think of <code>__objs__</code> as a table of all the Python objects in the storage:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=cl><span class=k>SELECT</span><span class=w> </span><span class=n>a0</span><span class=p>,</span><span class=w> </span><span class=n>y</span><span class=p>,</span><span class=w> </span><span class=n>X</span><span class=p>,</span><span class=w> </span><span class=n>trees</span><span class=p>,</span><span class=w> </span><span class=n>forest_acc</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>FROM</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>__objs__</span><span class=p>.</span><span class=n>obj</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>a0</span><span class=p>,</span><span class=w> </span><span class=n>__objs__</span><span class=p>.</span><span class=n>obj</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>X</span><span class=p>,</span><span class=w> </span><span class=n>__objs__</span><span class=p>.</span><span class=n>obj</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>y</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>__objs__</span><span class=p>.</span><span class=n>obj</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>trees</span><span class=p>,</span><span class=w> </span><span class=n>__objs__</span><span class=p>.</span><span class=n>obj</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=n>forest_acc</span><span class=p>,</span><span class=w> </span><span class=p>...</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>WHERE</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>generate_data</span><span class=p>.</span><span class=n>output_0</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>X</span><span class=w> </span><span class=k>and</span><span class=w> </span><span class=n>generate_data</span><span class=p>.</span><span class=n>output_1</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>y</span><span class=w> </span><span class=k>and</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>train_forest</span><span class=p>.</span><span class=n>X</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>X</span><span class=w> </span><span class=k>and</span><span class=w> </span><span class=n>train_forest</span><span class=p>.</span><span class=n>y</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>y</span><span class=w> </span><span class=k>and</span><span class=w> 
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>train_forest</span><span class=p>.</span><span class=n>a0</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>a0</span><span class=w> </span><span class=k>and</span><span class=w> </span><span class=n>train_forest</span><span class=p>.</span><span class=n>output_0</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>trees</span><span class=w> </span><span class=k>and</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>eval_forest</span><span class=p>.</span><span class=n>trees</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>trees</span><span class=w> </span><span class=k>and</span><span class=w> </span><span class=n>eval_forest</span><span class=p>.</span><span class=n>X</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>X</span><span class=w> </span><span class=k>and</span><span class=w> </span><span class=n>eval_forest</span><span class=p>.</span><span class=n>y</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>y</span><span class=w> </span><span class=k>and</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>eval_forest</span><span class=p>.</span><span class=n>output_0</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=n>forest_acc</span><span class=w>
</span></span></span></code></pre></div><h3 id=pattern-matching-with-collections-the-color-refinement-projection>Pattern-matching with collections: the color refinement projection</h3><p>You can propagate more complex relationships through the declarative interface,
such as ones between a collection and its elements. This allows you to query
programs that combine multiple objects in a single result (e.g., data
aggregation, model ensembling, processing data in chunks, ...) and/or generate a
variable number of objects (e.g., clustering, ...).</p><p>To illustrate, suppose that just for fun we disrupt the nice flow of our program
by slicing into the list of trees to evaluate only on the first half:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>with</span> <span class=n>storage</span><span class=o>.</span><span class=n>run</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>generate_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>n_trees</span> <span class=ow>in</span> <span class=n>wrap</span><span class=p>((</span><span class=mi>10</span><span class=p>,</span> <span class=mi>15</span><span class=p>,</span> <span class=mi>20</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=n>trees</span> <span class=o>=</span> <span class=n>train_forest</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>n_trees</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>forest_acc</span> <span class=o>=</span> <span class=n>eval_forest</span><span class=p>(</span><span class=n>trees</span><span class=p>[:</span><span class=n>n_trees</span> <span class=o>//</span> <span class=mi>2</span><span class=p>],</span> <span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>
</span></span></code></pre></div><p>If you look at how <code>forest_acc</code> is computed now, you get a substantially larger
graph:</p><img src=../../expanded_graph.svg width=85% style=display:block;margin-left:auto;margin-right:auto><p>The problem is that there are now six (apparently, for <code>n_trees=20</code>, 12 or 13
trees survived the filtering!) chains of "get an element from <code>trees</code>, put it in
a new list" computations in this graph that are redundant (they look exactly the
same) and at the same time tie the graph to a particular value of <code>n_trees</code>.
This will make the query both slow and too specific for our needs.</p><p>There is a principled solution to eliminate such repetition from any
computational graph: a modified <a href=https://en.wikipedia.org/wiki/Colour_refinement_algorithm>color refinement
algorithm</a>. There's
too many details for the scope of this blog post, but the overall intuition
is that you can project<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> any computational graph to a
smaller graph where there are no two vertices that "look the same" in the
context of the entire computation<sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup>. Here is what you get when you run <code>storage.draw_graph(forest_acc, project=True)</code>:</p><img src=../../projected_graph.svg width=50% style=display:block;margin-left:auto;margin-right:auto><p>And here is the code for this graph that you get using
<code>storage.print_graph(forest_acc, project=True)</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>idx0</span> <span class=o>=</span> <span class=n>Q</span><span class=p>()</span> <span class=c1># index into list</span>
</span></span><span class=line><span class=cl><span class=n>idx1</span> <span class=o>=</span> <span class=n>Q</span><span class=p>()</span> <span class=c1># index into list</span>
</span></span><span class=line><span class=cl><span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>generate_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>n_trees</span> <span class=o>=</span> <span class=n>Q</span><span class=p>()</span> <span class=c1># input to computation; can match anything</span>
</span></span><span class=line><span class=cl><span class=n>trees</span> <span class=o>=</span> <span class=n>train_forest</span><span class=p>(</span><span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y</span><span class=p>,</span> <span class=n>n_trees</span><span class=o>=</span><span class=n>n_trees</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>a0</span> <span class=o>=</span> <span class=n>trees</span><span class=p>[</span><span class=n>idx1</span><span class=p>]</span> <span class=c1># a0 will match any element of a match for trees at index matching idx1</span>
</span></span><span class=line><span class=cl><span class=n>a1</span> <span class=o>=</span> <span class=n>ListQ</span><span class=p>(</span><span class=n>elts</span><span class=o>=</span><span class=p>[</span><span class=n>a0</span><span class=p>],</span> <span class=n>idxs</span><span class=o>=</span><span class=p>[</span><span class=n>idx0</span><span class=p>])</span> <span class=c1># a1 will match any list containing a match for a0 at index idx0</span>
</span></span><span class=line><span class=cl><span class=n>forest_acc</span> <span class=o>=</span> <span class=n>eval_forest</span><span class=p>(</span><span class=n>trees</span><span class=o>=</span><span class=n>a1</span><span class=p>,</span> <span class=n>X</span><span class=o>=</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=o>=</span><span class=n>y</span><span class=p>)</span>
</span></span></code></pre></div><p>Note how the two indices <code>idx0, idx1</code> are different variables. This means that
the result of this query will be larger than it intuitively needs to be, because
there will be matches for one index in <code>trees</code> and another index in
<code>trees[:n_trees//2]</code>. You can restrict it further by making <code>idx0, idx1</code> the
same variable.</p><h2 id=per-call-versioning-and-dependency-tracking>Per-call versioning and dependency tracking</h2><p>So far, we've treated memoized functions as unchanging, but that's quite
unrealistic. One of the thorniest problems of data management is maintaining a
clear relationship between code and data in the face of changes in the internal
logic of a project's building blocks:</p><ul><li><strong>if you ignore a change in logic</strong>, you generally end up with a mixture of
results that <em>look</em> homogeneous to the system, but differ in the way they were
generated. This makes comparisons between them more or less meaningless.</li><li><strong>if every change is automatically marked as a change in logic</strong> (looking at
you, <code>git</code>), executions of
semantically equivalent code will be confusingly scattered across versions.
This makes comparisons between them difficult to program, and deters users
from code quality improvements.</li></ul><p>An automatic and universal solution to this problem is
<a href=https://stackoverflow.com/a/1132167/6538618>fundamentally impossible</a>. What
<code>mandala</code> offers instead is:</p><ul><li><strong>per-call dependency tracking</strong>: automatically track the functions and global
variables accessed by each memoized call, and alert you to changes in them, so
you can (carefully) choose whether a change to a dependency requires
recomputation of dependent calls</li><li><strong>content-addressable versions</strong>: use the current state of each dependency in
your codebase to automatically determine the currently compatible versions of
each memoized function to use in computation and queries. In particular, this
means that:<ul><li><strong>you can go "back in time"</strong> and access the storage relative to an earlier
state of the code (or even branch away in a new direction like in <code>git</code>) by
just restoring this state</li><li><strong>the code is the truth</strong>: when in doubt about the meaning of a result, you
can just look at the current code.</li></ul></li></ul><h3 id=warmup-adding-an-argument-backward-compatibly>Warmup: adding an argument backward-compatibly</h3><p>A very common type of change in practice is to have a function you've run a few
times, and then get an idea for how it could do its work differently (e.g. use a
new algorithm, or vary a previously hardcoded constant). Importantly, you want
to keep the old results around, but also somehow distinguish them from the new
ones.</p><p>In <code>mandala</code>, you can do this by adding an argument <strong>with a default value</strong>,
and it JustWorks‚Ñ¢. A column is added to the function's memoization table, with
the default value applied retroactively to past calls. All the memoized calls
without the new argument are still memoized. When doing this with a versioned
storage, you'll be shown a diff and should mark the change as <strong>not</strong> requiring
recomputation of dependents:</p><p><details open><summary markdown=span>Show/hide video</summary>
<video width=100% controls>
<source src=../../videos/add_arg.mp4 type=video/mp4><source src=../../videos/add_arg.webm type=video/webm>Your browser does not support HTML5 video.</video></details></p><h3 id=marking-changes-as-breaking-and-traveling-back-in-time>Marking changes as breaking and traveling back in time</h3><p>When you discover a bug affecting results, or just want to change how a function
works and recompute everything that depends on it, you mark the change as
requiring recomputation in the diff dialog. This will essentially tell the
storage that this function now "means something else" (under the hood, it has a
different <em>semantic id</em> from the previous version).</p><p>If you want to revisit the old results, restore the code to the old state; this
will cause the storage to interpret the function according to its previous
meaning in both computation and queries. You can examine the "shallow" versions
of a dependency (i.e. the revisions of its own source code) with
<code>storage.sources(f)</code>, and the "deep" versions (which include sets of
dependencies as seen by calls to this function) with <code>storage.versions(f)</code>:</p><p><details open><summary markdown=span>Show/hide video</summary>
<video width=100% controls>
<source src=../../videos/versioning.mp4 type=video/mp4><source src=../../videos/versioning.webm type=video/webm>Your browser does not support HTML5 video.</video></details></p><h2 id=conclusion>Conclusion</h2><p>This was a rather brisk walk through <code>mandala</code>, but it hopefully gave you an
idea of its general spirit and the particular ways in which it simplifies
computational data management. Some features that were not mentioned here, but
are currently in the works:</p><ul><li><strong>batch execution</strong>: separate data management and execution concerns in cases
when it's more efficient to run function calls in batches, such as inference on
large machine learning models. Code inside a <code>with storage.batch()</code> context is executed by a custom (batched) executor that you
can implement, yet each call is individually memoized and queriable.</li><li><strong>parallelization</strong>: since <code>mandala</code> is function-based, it's a great fit for
function-based parallelization frameworks like <a href=https://www.dask.org/><code>dask</code></a>.</li><li><strong>deletion interfaces</strong>: an imperative/declarative deletion interface,
analogous to the imperative/declarative query interfaces. Just change <code>with storage.run()</code> to <code>with storage.delete()</code>.</li></ul><p>We invite you to try <code>mandala</code> for your own projects and welcome contributions
to help improve its performance and capabilities!</p><h3 id=acknowledgements>Acknowledgements</h3><p>Thanks to Stefan Krastanov, Melody Guan and Ben Kuhn for providing feedback on
drafts of this post.</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>in the sense of a surjective labeled <a href=https://en.wikipedia.org/wiki/Graph_homomorphism>graph homomorphism</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p>this works in almost all practical cases. However, there exist instances
in which the color refinement algorithm fails to distinguish two vertices in
the graph that do in fact have a differen role in the computation. When in
doubt, read the code for the computational graph printed during queries to
make sure it captures the relationships you want to capture.&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div>
</article>

</body>
</html>
