<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Alex Makelov</title>
  <meta name="description" content="Personal website of Alex Makelov - researcher in mechanistic interpretability of large language models.">
  <link rel="stylesheet" href="/style.css">
</head>
<body>

<h1>Alex Makelov</h1>

<p>
  I currently work on mechanistic interpretability in industry. 
</p>

<p>
  I got my PhD in computer science from MIT, where I was advised by
  <a href="https://madry.mit.edu/">Prof. Aleksander Madry</a>. Before starting at MIT,
  I did Part III of the Mathematical Tripos at Cambridge University, with coursework
  in combinatorics and algebra. And before that, I earned a BA, with a joint
  concentration in math and computer science, at Harvard College, where I worked
  with <a href="https://salil.seas.harvard.edu/">Prof. Salil Vadhan</a>.
</p>

<p>
  I'm also broadly interested in the research, design and implementation of
  tools that make the work of scientists and practitioners in computational
  fields easier. As part of this, I used to work on <a
  href="https://github.com/amakelov/mandala">mandala</a>, a Python library to
  simplify scientific data management.
</p>

<p>
  <a href="https://scholar.google.com/citations?user=haO4sKoAAAAJ&hl=en&oi=ao">Google Scholar</a> |
  <a href="https://www.semanticscholar.org/author/Aleksandar-Makelov/17775913">Semantic Scholar</a> |
  <a href="https://x.com/AMakelov">Twitter</a>
</p>

<h2>Publications</h2>

<div class="publications">

<p>
  <a href="https://arxiv.org/abs/2506.19823">Persona Features Control Emergent Misalignment</a><br>
  M. Wang*, T. Dupr√© la Tour*, O. Watkins*, A. Makelov*, R. Chi*, S. Miserendino, J. Wang, A. Rajaram, J. Heidecke, T. Patwardhan, D. Mossing*<br>
  <em>arXiv preprint</em>
</p>

<p>
  <a href="https://openreview.net/attachment?id=JdrVuEQih5&name=pdf">Sparse Autoencoders Match Supervised Features for Model Steering on the IOI Task</a><br>
  A. Makelov<br>
  <strong>Spotlight</strong>, ICML 2024 Workshop on Mechanistic Interpretability<br>
  <em>See also</em>: <a href="https://www.alignmentforum.org/posts/zj3GKWAnhPgTARByB/saes-discover-meaningful-features-in-the-ioi-task">AI Alignment Forum post</a>
</p>

<p>
  <a href="https://arxiv.org/abs/2405.08366">Towards Principled Evaluations of Sparse Autoencoders for Interpretability and Control</a><br>
  A. Makelov*, G. Lange*, N. Nanda<br>
  <em>ICLR 2025</em>
</p>

<p>
  <a href="scipy-mandala.pdf"><code>mandala</code>: Compositional Memoization for Simple & Powerful Scientific Data Management</a><br>
  A. Makelov<br>
  <em>SciPy 2024 Proceedings</em>
</p>

<p>
  <a href="https://arxiv.org/abs/2311.17030">Is This the Subspace You Are Looking for? An Interpretability Illusion for Subspace Activation Patching</a><br>
  A. Makelov*, G. Lange*, N. Nanda<br>
  ICLR 2024
</p>

<p>
  <a href="https://openreview.net/pdf?id=4NT3umNU3D0">Backdoor or Feature? A New Perspective on Data Poisoning</a><br>
  A. Khaddaj*, G. Leclerc*, A. Makelov*, K. Georgiev, A. Ilyas, H. Salman, A. Madry<br>
  ICML 2023
</p>

<p>
  <a href="https://arxiv.org/abs/1706.06083">Towards Deep Learning Models Resistant to Adversarial Attacks</a><br>
  A. Madry, A. Makelov, L. Schmidt, D. Tsipras, A. Vladu<br>
  ICLR 2018
</p>

<p>
  <a href="https://dash.harvard.edu/bitstream/handle/1/14398532/MAKELOV-SENIORTHESIS-2015.pdf?sequence=1">Expansion in Lifts of Graphs</a><br>
  A. Makelov<br>
  Undergraduate Thesis, Harvard College 2015
</p>

</div>

<h2>Blog</h2>

<p>
  <a href="blog/deps/">Practical dependency tracking for Python function calls</a> (June '23)
</p>
<p>
  <a href="blog/pl/">Mandala: Python programs that save, query and version themselves</a> (April '23)
</p>

</body>
</html>
